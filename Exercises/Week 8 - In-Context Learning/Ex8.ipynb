{"cells":[{"cell_type":"markdown","id":"ac671356","metadata":{"id":"ac671356"},"source":["#  Exercise 8: In-Context Learning with GPT-3.5"]},{"cell_type":"markdown","id":"7fc96df3","metadata":{"id":"7fc96df3"},"source":["<div style=\"padding:15px 20px 20px 20px;border-left:3px solid green;background-color:#e4fae4;border-radius: 20px;\">\n","\n","## **Exercise Description**\n","- In this exercise, you will investigate in-context learning using OpanAI GPT-3.5 model. This exercise contains two parts.\n","\n","- In the first part, you will investigate in-context learning for classification based on a natural language inference (NLI) task.\n","    \n","- In the second part, you will investigate in-context learning for generation based on a story ending generation (SEG) task.\n","\n","\n","### Table of Contents\n","- **[PART 1: In-Context Learning for Natural Langauge Inference](#1)**\n","    - [1.1 Compare Different Shots](#11)\n","    - [1.2 Effect of Neutral In-Context Examples](#12)\n","    - [1.3 Play with Different Verbalizers](#13)\n","    - [1.4 Add Instructions](#14)\n","- **[PART 2: In-Context Learning for Story Ending Generation](#2)**\n","    - [2.1 Zero-Shot Generation](#21)\n","    - [2.2 Few-Shot Generation](#22)\n","    - [2.3 Add Instructions](#23)\n","\n","</div>"]},{"cell_type":"markdown","id":"ff70873e","metadata":{"id":"ff70873e"},"source":["## Setup Your Environment\n","\n","**Note: the Python version for this exercise is 3.9**, please install the following required packages."]},{"cell_type":"code","source":["# if you are using Google Colab\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"iLBx5JbP0xNR"},"id":"iLBx5JbP0xNR","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fill in the path where you put the Exercise folder into\n","ROOT_PATH = \"/content/drive/...\""],"metadata":{"id":"L52FF8Hn1AWC"},"id":"L52FF8Hn1AWC","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"a9a720ab","metadata":{"scrolled":false,"id":"a9a720ab"},"outputs":[],"source":["!pip install numpy==1.22.4\n","!pip install tqdm==4.65.0\n","!pip install nltk==3.8.1"]},{"cell_type":"markdown","id":"623e14fd","metadata":{"id":"623e14fd"},"source":["You also need to install our **GPT-3.5 wrapper** to interact with OpenAI GPT-3.5 models for free."]},{"cell_type":"code","execution_count":null,"id":"3d4c8ba5","metadata":{"id":"3d4c8ba5"},"outputs":[],"source":["!pip install {ROOT_PATH}gpt_wrapper-0.0.7-py3-none-any.whl"]},{"cell_type":"markdown","id":"d4d0ca95","metadata":{"id":"d4d0ca95"},"source":["Import the required packages for this exercise, including our GPT-3.5 wrapper."]},{"cell_type":"code","execution_count":null,"id":"8d81dd37","metadata":{"id":"8d81dd37"},"outputs":[],"source":["import json\n","import numpy as np\n","from tqdm import tqdm\n","import random\n","from copy import deepcopy\n","import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","from nltk.tokenize import word_tokenize\n","from nltk.translate.meteor_score import meteor_score\n","\n","import gpt_wrapper\n","from gpt_wrapper.chat import Chat"]},{"cell_type":"markdown","id":"3049b54b","metadata":{"id":"3049b54b"},"source":["To facilitate reproduction, we fix a random seed here."]},{"cell_type":"code","execution_count":null,"id":"acca193e","metadata":{"id":"acca193e"},"outputs":[],"source":["seed = 233"]},{"cell_type":"markdown","id":"721322d2","metadata":{"id":"721322d2"},"source":["Enter the exercise API key to get access to our GPT-3.5 wrapper."]},{"cell_type":"code","execution_count":null,"id":"cd376243","metadata":{"id":"cd376243"},"outputs":[],"source":["gpt_wrapper.api_key = \"a5a244d0-2f56-41d3-ac99-9e5efb0e4079\""]},{"cell_type":"markdown","id":"11e49157","metadata":{"id":"11e49157"},"source":["<a name=\"1\"></a>\n","## **PART 1: In-Context Learning for Natural Language Inference**\n","---\n","\n","In this part, you are going to use the GPT-3.5 model to solve the [natural language inference (NLI)](https://towardsdatascience.com/natural-language-inference-an-overview-57c0eecf6517) task based on in-context learning. For this task, model needs to classify the relation of two given sentences (premise and hypothesis) into three classes: entailment, neutral and contradiction."]},{"cell_type":"markdown","id":"ed303c88","metadata":{"id":"ed303c88"},"source":["Here you can take a glance of the training data used for sampling few-shot in-context examples, and the testing data used to query GPT-3.5 language model for classification (along with the gold answers for evaluation)."]},{"cell_type":"code","execution_count":null,"id":"f8ee990d","metadata":{"id":"f8ee990d"},"outputs":[],"source":["with open(ROOT_PATH+\"nli_classification/train_classification.json\", \"r\") as f:\n","    train_samples = json.load(f)\n","with open(ROOT_PATH+\"nli_classification/test_classification.json\", \"r\") as f:\n","    test_data = json.load(f)\n","\n","print(\"Training Samples:\")\n","print(train_samples[\"entailment\"][0])\n","print(\"\\n\")\n","\n","print(\"Testing Query:\")\n","print(test_data[0][\"query\"])\n","print(\"\\n\")\n","\n","print(\"Gold Answer:\")\n","print(test_data[0][\"gold_answer\"])"]},{"cell_type":"markdown","id":"01caddef","metadata":{"id":"01caddef"},"source":["Here is the GPT-3.5 hyperparameter setting for this NLI task.\n","\n","**max_tokens**: Maximum number of tokens to generate, default to 16.\n","\n","**temperature**: Sampling temperature to use, between 0.0 and 2.0, default to 1.0. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n","\n","**top_p**: Nucleus sampling factor (alternative to sampling with temperature), between 0.0 and 1.0, default to 1.0. The model randomly samples from the tokens with top_p probability mass.\n","\n","**presence_penalty**: Between -2.0 and 2.0, default to 0.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n","\n","**frequency_penalty**: Between -2.0 and 2.0, default to 0.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim."]},{"cell_type":"markdown","source":["We choose a small *max_tokens* because only the first non-space token generated by the model is used as the predicted class (i.e., verbalizer).\n","\n","We also change the *temparature* to zero in order to let the model make deterministic classification decisions."],"metadata":{"id":"HN3X2CRHdUmW"},"id":"HN3X2CRHdUmW"},{"cell_type":"code","execution_count":null,"id":"ab3bc651","metadata":{"id":"ab3bc651"},"outputs":[],"source":["model_args={\"max_tokens\": 2, \"temperature\": 0.0, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0}"]},{"cell_type":"markdown","id":"4ab97e5d","metadata":{"id":"4ab97e5d"},"source":["You will evaluate the model's NLI performance based on the accuracy and F1 scores on each class."]},{"cell_type":"code","execution_count":null,"id":"f6129f62","metadata":{"id":"f6129f62"},"outputs":[],"source":["def evaluate_nli(predictions, gold_labels, mapping):\n","    \n","    counter = np.zeros((3, 3))  # three-class confusion matrix\n","    \n","    # calculate the confusion matrix\n","    for p, g in zip(predictions, gold_labels):\n","        pid = mapping[p]\n","        gid = mapping[g]\n","        counter[gid][pid] += 1\n","    \n","    print()\n","    print(counter)\n","    \n","    pred_sum = np.sum(counter, axis=0)  # total number of predictions on each class\n","    gold_sum = np.sum(counter, axis=1)  # total number of test samples (gold labels) on each class\n","    diag = np.diagonal(counter)  # total number of correct predictions on each class\n","    \n","    acc = np.sum(diag) / np.sum(counter)  # accuracy\n","    \n","    f1 = [0, 0, 0]\n","    for cid in range(3):\n","        precision = diag[cid] / pred_sum[cid]  # precisions on each class\n","        recall = diag[cid] / gold_sum[cid]  # recalls on each class\n","        f1[cid] = 2 * precision * recall / (precision + recall)  # F1 scores on each class\n","    \n","    return acc, f1[0], f1[1], f1[2]"]},{"cell_type":"markdown","id":"d886b1c6","metadata":{"id":"d886b1c6"},"source":["You will use the following function to perform GPT-3.5 inference on the NLI task based on in-context learning."]},{"cell_type":"code","execution_count":null,"id":"7a878781","metadata":{"id":"7a878781"},"outputs":[],"source":["def gpt3_nli(train_samples, test_data, shots, predictions, gold_answers,\n","             introduction=None, default_class=\"neutral\", task_name=\"none\"):\n","    \n","    '''\n","    train_samples: training data for sampling in-context examples\n","    train_data: testing queries (with gold labels)\n","    shots: number of in-context examples (shots) per class\n","    predictions: cache for saving the model predictions\n","    gold_answers: cache for saving gold answers\n","    introduction: additional task introduction for prompting\n","    default_class: default prediction class if the generated token is not among the verbalizers of three NLI classes\n","    task_name: task name for creating chat sessions\n","    '''\n","    \n","    # randomly sample in-context examples\n","    examples = []\n","    for nli_class, samples in train_samples.items():\n","        few_shot_samples = random.sample(samples, shots[nli_class])\n","        examples.extend(few_shot_samples)\n","\n","    random.shuffle(examples)  # randomly shuffle sampled in-context examples\n","    \n","    # add task introduction (if it exists) before in-context examples for better prompting\n","    if introduction:\n","        examples.insert(0, introduction)\n","\n","    for qid, query in enumerate(tqdm(test_data)):\n","        \n","        if qid < len(predictions):  # skip this query if its model prediction is already saved in cache\n","            continue\n","\n","        # concatenate all the in-context examples with the query, to get the final input demonstration\n","        demonstration = \"\\n\\n\".join(examples+[query[\"query\"]])\n","\n","        # create a chat session using our GPT-3.5 wrapper class Chat\n","        chat = Chat.create(name=task_name+\"_\"+str(qid))\n","        \n","        # use the created chat session to query the GPT-3.5 model with the input demonstration,\n","        # and get back model's output message\n","        message = chat.ask(demonstration, model_args=model_args)\n","        \n","        # model's output text is in the attribute \"content\",\n","        # we use the first token of the generated text as the prediction\n","        preds = message.content.strip().split()\n","        if preds:\n","            pred = preds[0].lower()\n","        else:\n","            pred = \"none\"\n","        \n","        # mapping similar outputs to class verbalizers\n","        if pred in [\"entail\", \"entailed\", \"entailing\"]:\n","            pred = \"entailment\"\n","        if pred in [\"contrad\", \"contradict\", \"contradicted\", \"contradicting\"]:\n","            pred = \"contradiction\"\n","        \n","        # save the prediction in chace\n","        if pred in train_samples.keys():\n","            predictions.append(pred)\n","        else:\n","            predictions.append(default_class)\n","        \n","        # save the gold answer in chace for evaluation\n","        gold_answers.append(query[\"gold_answer\"])"]},{"cell_type":"markdown","id":"a6619024","metadata":{"id":"a6619024"},"source":["You will run the following function to perform GPT-3.5 inference and evaluation."]},{"cell_type":"code","execution_count":null,"id":"692af4be","metadata":{"id":"692af4be"},"outputs":[],"source":["def run(train_samples, test_data, class_shots, mapping, predictions, gold_answers,\n","        introduction=None, default_class=\"neutral\", task_name=\"none\"):\n","    try:\n","\n","        gpt3_nli(train_samples, test_data, class_shots, predictions, gold_answers,\n","                 introduction=introduction, default_class=default_class, task_name=task_name)\n","        \n","        acc, f1_ent, f1_neu, f1_con = evaluate_nli(predictions, gold_answers, mapping)\n","        macro_f1 = (f1_ent + f1_neu + f1_con) / 3\n","\n","        print(f'Accuracy: {acc*100:.2f}% | F1: ({f1_ent*100:.2f}%, {f1_neu*100:.2f}%, {f1_con*100:.2f}%) | Macro-F1: {macro_f1*100:.2f}%')\n","\n","    except Exception as error:  # OpenAI ChatGPT endpoint (gpt-3.5-turbo) may get stucked by too many queries from time to time\n","    \n","        print(error)\n"]},{"cell_type":"markdown","id":"c90ea96b","metadata":{"id":"c90ea96b"},"source":["<a name=\"11\"></a>\n","### **1.1 Compare Different Shots**\n","\n","In this part, you will compare GPT-3.5 performances under different shots (number) of in-context examples."]},{"cell_type":"markdown","id":"2f25d6a1","metadata":{"id":"2f25d6a1"},"source":["#### 0-shot classification:\n","\n","Do not provide any in-context learning examples to the model.\n","\n","Create empty caches for saving model predictions and gold answers."]},{"cell_type":"code","execution_count":null,"id":"0ae867da","metadata":{"id":"0ae867da"},"outputs":[],"source":["predictions = []\n","gold_answers = []"]},{"cell_type":"markdown","id":"3921da49","metadata":{"id":"3921da49"},"source":["Run the inferece and evaluation.\n","\n","**Note:** OpenAI ChatGPT endpoint may sometimes get stucked by too many queries. If running the following cell gets stucked, just re-run it, and inference will continue from the stucked query. However, do not re-run the above cell for creating the caches, which will clear the already saved predictions."]},{"cell_type":"code","execution_count":null,"id":"78fa56d7","metadata":{"id":"78fa56d7"},"outputs":[],"source":["random.seed(seed)\n","np.random.seed(seed)\n","\n","class_shots = {\"entailment\": 0, \"neutral\": 0, \"contradiction\": 0}\n","mapping = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n","\n","run(train_samples, test_data, class_shots, mapping, predictions, gold_answers, task_name=\"1_1_shots0\")"]},{"cell_type":"markdown","id":"158536b5","metadata":{"id":"158536b5"},"source":["#### 1-shot per class:\n","\n","For each class, provide 1 in-context learning example sampled from the training data.\n","\n","Clear the caches."]},{"cell_type":"code","execution_count":null,"id":"6bd54af4","metadata":{"id":"6bd54af4"},"outputs":[],"source":["predictions = []\n","gold_answers = []"]},{"cell_type":"markdown","id":"a43cb520","metadata":{"id":"a43cb520"},"source":["Re-run the inference and evaluation"]},{"cell_type":"code","execution_count":null,"id":"f544c0fd","metadata":{"id":"f544c0fd"},"outputs":[],"source":["random.seed(seed)\n","np.random.seed(seed)\n","\n","class_shots = {\"entailment\": 1, \"neutral\": 1, \"contradiction\": 1}\n","mapping = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n","\n","run(train_samples, test_data, class_shots, mapping, predictions, gold_answers, task_name=\"1_1_shots1\")"]},{"cell_type":"markdown","id":"1f2eb071","metadata":{"id":"1f2eb071"},"source":["#### 2-shot per class:\n","\n","Try 2 in-context learning examples per class."]},{"cell_type":"code","execution_count":null,"id":"3ae49ee1","metadata":{"id":"3ae49ee1"},"outputs":[],"source":["predictions = []\n","gold_answers = []"]},{"cell_type":"code","execution_count":null,"id":"143c7eba","metadata":{"id":"143c7eba"},"outputs":[],"source":["random.seed(seed)\n","np.random.seed(seed)\n","\n","class_shots = {\"entailment\": 2, \"neutral\": 2, \"contradiction\": 2}\n","mapping = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n","\n","run(train_samples, test_data, class_shots, mapping, predictions, gold_answers, task_name=\"1_1_shots2\")"]},{"cell_type":"markdown","id":"ae6f41c3","metadata":{"id":"ae6f41c3"},"source":["#### 3-shot per class:\n","\n","Try 3 in-context learning examples per class."]},{"cell_type":"code","execution_count":null,"id":"c86dc6c2","metadata":{"id":"c86dc6c2"},"outputs":[],"source":["predictions = []\n","gold_answers = []"]},{"cell_type":"code","execution_count":null,"id":"32278700","metadata":{"id":"32278700"},"outputs":[],"source":["random.seed(seed)\n","np.random.seed(seed)\n","\n","class_shots = {\"entailment\": 3, \"neutral\": 3, \"contradiction\": 3}\n","mapping = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n","\n","run(train_samples, test_data, class_shots, mapping, predictions, gold_answers, task_name=\"1_1_shots3\")"]},{"cell_type":"markdown","id":"fcca3308","metadata":{"id":"fcca3308"},"source":["**Questions:**\n","\n","1. Can model handle well the NLI task without in-context examples for learning (i.e., under the 0-shot setting)?\n","2. On detecting which class are the in-context examples most helpful? and most helpless?\n","3. Is the more in-context examples the better?"]},{"cell_type":"markdown","id":"ae87231e","metadata":{"id":"ae87231e"},"source":["<a name=\"12\"></a>\n","### **1.2 Effect of Neutral In-Context Examples**\n","\n","Try 3-shot in-context examples on the entailment and contradictions classes, but do not provide any examples on the neutral class."]},{"cell_type":"code","execution_count":null,"id":"f6d78c89","metadata":{"id":"f6d78c89"},"outputs":[],"source":["predictions = []\n","gold_answers = []"]},{"cell_type":"code","execution_count":null,"id":"ae734042","metadata":{"id":"ae734042"},"outputs":[],"source":["random.seed(seed)\n","np.random.seed(seed)\n","\n","class_shots = {\"entailment\": 3, \"neutral\": 0, \"contradiction\": 3}\n","mapping = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n","\n","run(train_samples, test_data, class_shots, mapping, predictions, gold_answers, task_name=\"1_2\")"]},{"cell_type":"markdown","id":"e8ef6a43","metadata":{"id":"e8ef6a43"},"source":["**Question:** What do you find here?"]},{"cell_type":"markdown","id":"77c56bf9","metadata":{"id":"77c56bf9"},"source":["<a name=\"13\"></a>\n","### **1.3 Play with Different Verbalizers**\n","\n","In this part, you will try to use different verbalizers for this NLI classification task. Instead of using *entailment*, *neutral* and *contradiction*, you will try the following two alternatives:\n","\n","- *positive*, *unrelated* and *negative*\n","- *a*, *b* and *c*"]},{"cell_type":"markdown","id":"f9f7e4f2","metadata":{"id":"f9f7e4f2"},"source":["Build data with the above two different verbalizers."]},{"cell_type":"code","execution_count":null,"id":"88f33a23","metadata":{"id":"88f33a23"},"outputs":[],"source":["mapping_to_pun = {\"entailment\": \"positive\", \"neutral\": \"unrelated\", \"contradiction\": \"negative\"}\n","train_samples_pun = {\"positive\": [], \"unrelated\": [], \"negative\": []}\n","test_data_pun = []\n","\n","mapping_to_abc = {\"entailment\": \"a\", \"neutral\": \"b\", \"contradiction\": \"c\"}\n","train_samples_abc = {\"a\": [], \"b\": [], \"c\": []}\n","test_data_abc = []\n","\n","for nli_class, samples in train_samples.items():\n","    \n","    nli_class_pun = mapping_to_pun[nli_class]\n","    nli_class_abc = mapping_to_abc[nli_class]\n","    \n","    for sample in samples:\n","        \n","        sample_pun = \" \".join(sample.split(\" \")[:-1] + [nli_class_pun])\n","        train_samples_pun[nli_class_pun].append(sample_pun)\n","        \n","        sample_abc = \" \".join(sample.split(\" \")[:-1] + [nli_class_abc])\n","        train_samples_abc[nli_class_abc].append(sample_abc)\n","    \n","for query in test_data:\n","    \n","    query_pun = deepcopy(query)\n","    query_pun[\"gold_answer\"] = mapping_to_pun[query[\"gold_answer\"]]\n","    test_data_pun.append(query_pun)\n","    \n","    query_abc = deepcopy(query)\n","    query_abc[\"gold_answer\"] = mapping_to_abc[query[\"gold_answer\"]]\n","    test_data_abc.append(query_abc)"]},{"cell_type":"markdown","id":"fc11b99e","metadata":{"id":"fc11b99e"},"source":["You can take a glance of the processed training and testing data with different verbalizers.\n","\n","Data with verbalizers *positive*, *unrelated* and *negative*"]},{"cell_type":"code","execution_count":null,"id":"7ae7c0de","metadata":{"id":"7ae7c0de"},"outputs":[],"source":["print(\"Training Samples:\")\n","print(train_samples_pun[\"positive\"][0])\n","print(\"\\n\")\n","\n","print(\"Testing Query:\")\n","print(test_data_pun[0][\"query\"])\n","print(\"\\n\")\n","\n","print(\"Gold Answer:\")\n","print(test_data_pun[0][\"gold_answer\"])"]},{"cell_type":"markdown","id":"a4783fca","metadata":{"id":"a4783fca"},"source":["Data with verbalizers *a*, *b* and *c*"]},{"cell_type":"code","execution_count":null,"id":"2f64c3cb","metadata":{"id":"2f64c3cb"},"outputs":[],"source":["print(\"Training Samples:\")\n","print(train_samples_abc[\"a\"][0])\n","print(\"\\n\")\n","\n","print(\"Testing Query:\")\n","print(test_data_abc[0][\"query\"])\n","print(\"\\n\")\n","\n","print(\"Gold Answer:\")\n","print(test_data_abc[0][\"gold_answer\"])"]},{"cell_type":"markdown","id":"eb30fd47","metadata":{"id":"eb30fd47"},"source":["#### Re-do the classification with new verbalizers.\n","\n","Try verbalizers *positive*, *unrelated* and *negative* under the 2-shot setting in 1.1"]},{"cell_type":"code","execution_count":null,"id":"14b52710","metadata":{"id":"14b52710"},"outputs":[],"source":["predictions = []\n","gold_answers = []"]},{"cell_type":"code","execution_count":null,"id":"3842ede7","metadata":{"id":"3842ede7"},"outputs":[],"source":["random.seed(seed)\n","np.random.seed(seed)\n","\n","class_shots_pun = {\"positive\": 2, \"unrelated\": 2, \"negative\": 2}\n","mapping_pun = {\"positive\": 0, \"unrelated\": 1, \"negative\": 2}\n","\n","run(train_samples_pun, test_data_pun, class_shots_pun, mapping_pun,\n","    predictions, gold_answers, default_class=\"unrelated\", task_name=\"1_3_pun\")"]},{"cell_type":"markdown","id":"5ada009a","metadata":{"id":"5ada009a"},"source":["Try verbalizers *a*, *b* and *c* under the 2-shot setting in 1.1"]},{"cell_type":"code","execution_count":null,"id":"f1efccae","metadata":{"id":"f1efccae"},"outputs":[],"source":["predictions = []\n","gold_answers = []"]},{"cell_type":"code","execution_count":null,"id":"df8194f6","metadata":{"id":"df8194f6"},"outputs":[],"source":["random.seed(seed)\n","np.random.seed(seed)\n","\n","class_shots_abc = {\"a\": 2, \"b\": 2, \"c\": 2}\n","mapping_abc = {\"a\": 0, \"b\": 1, \"c\": 2}\n","\n","run(train_samples_abc, test_data_abc, class_shots_abc, mapping_abc,\n","    predictions, gold_answers, default_class=\"b\", task_name=\"1_3_abc\")"]},{"cell_type":"markdown","id":"2c6f384d","metadata":{"id":"2c6f384d"},"source":["**Questions:**\n","\n","1. Are verbalizers *positive*, *unrelated* and *negative* better or worse than the original ones?\n","2. Are verbalizers *a*, *b* and *c* better or worse than the original ones?"]},{"cell_type":"markdown","id":"77c62887","metadata":{"id":"77c62887"},"source":["<a name=\"14\"></a>\n","### **1.4 Add Instructions**\n","\n","In this part, you will try to add high-level task instruction to the model input.\n","\n","Try 1-shot in-context learning with overall task introduction: \"Guess whether the given two sentences have an entailment, neutral or contradiction relation.\""]},{"cell_type":"code","execution_count":null,"id":"f123b9cb","metadata":{"id":"f123b9cb"},"outputs":[],"source":["predictions = []\n","gold_answers = []"]},{"cell_type":"code","execution_count":null,"id":"8252537f","metadata":{"id":"8252537f"},"outputs":[],"source":["random.seed(seed)\n","np.random.seed(seed)\n","\n","introduction = \"Guess whether the given two sentences have an entailment, neutral or contradiction relation.\"\n","class_shots = {\"entailment\": 1, \"neutral\": 1, \"contradiction\": 1}\n","mapping = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n","\n","run(train_samples, test_data, class_shots, mapping,\n","    predictions, gold_answers, introduction=introduction, task_name=\"1_4_intro1\")"]},{"cell_type":"markdown","id":"febb96f6","metadata":{"id":"febb96f6"},"source":["Try to use a more specified task introduction as the instruction: \"Guess whether the second statement is entailed by the first statement, contradicts the first statement, or is neutral to the first statement.\""]},{"cell_type":"code","execution_count":null,"id":"312ff74a","metadata":{"id":"312ff74a"},"outputs":[],"source":["predictions = []\n","gold_answers = []"]},{"cell_type":"code","execution_count":null,"id":"ffb6580f","metadata":{"id":"ffb6580f"},"outputs":[],"source":["random.seed(seed)\n","np.random.seed(seed)\n","\n","introduction = \"Guess whether the second statement is entailed by the first statement, contradicts the first statement, or is neutral to the first statement.\"\n","class_shots = {\"entailment\": 1, \"neutral\": 1, \"contradiction\": 1}\n","mapping = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n","\n","run(train_samples, test_data, class_shots, mapping,\n","    predictions, gold_answers, introduction=introduction, task_name=\"1_4_intro2\")"]},{"cell_type":"markdown","id":"8fed052d","metadata":{"id":"8fed052d"},"source":["Try to make the model think that he is an expert on doing this task! Use the instruction: \"Pretend that you are an expert of logic. Tell us whether the second statement is entailed by the first statement, contradicts the first statement, or is neutral to the first statement.\""]},{"cell_type":"code","execution_count":null,"id":"fbd84edc","metadata":{"id":"fbd84edc"},"outputs":[],"source":["predictions = []\n","gold_answers = []"]},{"cell_type":"code","execution_count":null,"id":"fb12f254","metadata":{"id":"fb12f254"},"outputs":[],"source":["random.seed(seed)\n","np.random.seed(seed)\n","\n","introduction = \"Pretend that you are an expert of logic. Tell us whether the second statement is entailed by the first statement, contradicts the first statement, or is neutral to the first statement.\"\n","class_shots = {\"entailment\": 1, \"neutral\": 1, \"contradiction\": 1}\n","mapping = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n","\n","run(train_samples, test_data, class_shots, mapping,\n","    predictions, gold_answers, introduction=introduction, task_name=\"1_4_intro3\")"]},{"cell_type":"markdown","id":"f17d0159","metadata":{"id":"f17d0159"},"source":["**Question:** Does additional task instruction help? Does more specific insturction tend to be better? Is it effective to give the model a role (e.g., expert) before doing the task?"]},{"cell_type":"markdown","id":"5c8f6131","metadata":{"id":"5c8f6131"},"source":["<a name=\"2\"></a>\n","## **PART 2: In-Context Learning for Story Ending Generation**\n","---\n","\n","In this part, you will switch to using the GPT-3.5 model to solve the story ending generation (SEG) task based on in-context learning. For this task, model is given four lines of story plot and needs to generate the fifth line of the story plot as an ending."]},{"cell_type":"markdown","id":"2f52dacd","metadata":{"id":"2f52dacd"},"source":["You can take a glance of the training data used for sampling few-shot in-context examples, and the testing data used to query GPT-3.5 language model for story completion (along with the reference story ending)."]},{"cell_type":"code","execution_count":null,"id":"2d31a9bd","metadata":{"id":"2d31a9bd"},"outputs":[],"source":["with open(ROOT_PATH+\"story_generation/train_generation.json\", \"r\") as f:\n","    train_samples_sg = json.load(f)\n","with open(ROOT_PATH+\"story_generation/test_generation.json\", \"r\") as f:\n","    test_data_sg = json.load(f)\n","\n","print(\"Training Samples:\")\n","print(train_samples_sg[0])\n","print(\"\\n\")\n","\n","print(\"Testing Query:\")\n","print(test_data_sg[0][\"query\"])\n","print(\"\\n\")\n","\n","print(\"Reference Story Ending:\")\n","print(test_data_sg[0][\"reference_ending\"])"]},{"cell_type":"markdown","id":"a8a56277","metadata":{"id":"a8a56277"},"source":["Here is the GPT-3.5 hyperparameter setting for this SEG task.\n","\n","We set *max_tokens* to be 20, which is supposed to be the maximum length of a story ending (i.e., a sentence).\n","\n","We also change the *temparature* and *top_p* to 0.9 in order to enable the model's creativity and make it generates more diverse story endings."]},{"cell_type":"code","execution_count":null,"id":"489af8bb","metadata":{"id":"489af8bb"},"outputs":[],"source":["model_args={\"max_tokens\": 20, \"temperature\": 0.9, \"top_p\": 0.9, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0}"]},{"cell_type":"markdown","id":"d59fcc7f","metadata":{"id":"d59fcc7f"},"source":["You will evaluate the model generation performance based on [METEOR](https://aclanthology.org/W05-0909.pdf). This metric is originally proposed to evaluate machine translation quality, but later widely used in evaluating open-domain text (e.g., dialogues and stories) generation. It measures the alignments (i.e., matches) between words in the hypothesis to reference, by sequentially applying exact match, stemmed match and wordnet based synonym match."]},{"cell_type":"code","execution_count":null,"id":"93f4a599","metadata":{"id":"93f4a599"},"outputs":[],"source":["def evaluate_sed(generation, reference):\n","    \n","    ref_tokens = word_tokenize(reference)\n","    gen_tokens = word_tokenize(generation)\n","    score = meteor_score([ref_tokens], gen_tokens)\n","    \n","    return score"]},{"cell_type":"markdown","id":"ff69d0d4","metadata":{"id":"ff69d0d4"},"source":["You will use the following function to perform GPT-3.5 generation on the SEG task based on in-context learning."]},{"cell_type":"code","execution_count":null,"id":"352adb17","metadata":{"id":"352adb17"},"outputs":[],"source":["def gpt3_seg(train_samples, test_data, shot, generations, queries, reference_endings,\n","             introduction=None, task_name=\"none\"):\n","\n","    '''\n","    train_samples: training data for sampling in-context examples\n","    train_data: testing queries (with reference story endings)\n","    shot: number of in-context examples\n","    generations: cache for saving the model generations\n","    queries: cache for saving the input queries (i.e., four-line stories to be completed)\n","    reference_endings: cache for reference story endings\n","    introduction: additional task introduction for prompting\n","    task_name: task name for creating chat sessions\n","    '''\n","    \n","    # randomly sample in-context examples and shuffle them\n","    examples = random.sample(train_samples, shot)\n","    random.shuffle(examples)\n","    \n","    # add task introduction (if it exists) before in-context examples for better prompting\n","    if introduction:\n","        examples.insert(0, introduction)\n","\n","    for qid, query in enumerate(tqdm(test_data)):\n","        \n","        if qid < len(generations):  # skip this query if its model generated story ending is already saved in cache\n","            continue\n","\n","        # concatenate all the in-context examples with the query, to get the final input demonstration\n","        demonstration = \"\\n\\n\".join(examples+[query[\"query\"]])\n","\n","        # create a chat session using our GPT-3.5 wrapper and query the model to get the story ending generation\n","        chat = Chat.create(name=task_name+\"_\"+str(qid))\n","        message = chat.ask(demonstration, model_args=model_args)\n","        \n","        # save the model generation, story query and reference ending in caches\n","        generations.append(message.content)\n","        queries.append(query[\"query\"])\n","        reference_endings.append(query[\"reference_ending\"])"]},{"cell_type":"markdown","id":"5b28953b","metadata":{"id":"5b28953b"},"source":["You will run the following function to perform GPT-3.5 generation and evaluation."]},{"cell_type":"code","execution_count":null,"id":"fe1e696a","metadata":{"id":"fe1e696a"},"outputs":[],"source":["def run(train_samples, test_data, shot, generations, queries, reference_endings, introduction=None, task_name=\"none\"):\n","    \n","    try:\n","        \n","        gpt3_seg(train_samples, test_data, shot,\n","                 generations, queries, reference_endings,\n","                 introduction=introduction, task_name=task_name)\n","\n","        meteor_scores = []\n","        print()\n","\n","        for qid, query in enumerate(queries):\n","\n","            meteor = evaluate_sed(generations[qid], reference_endings[qid])\n","            print(\"Query \"+str(qid+1)+f' METEOR Score: {meteor*100:.2f}') \n","\n","            meteor_scores.append(meteor)\n","\n","        meteor_avg = sum(meteor_scores)/len(meteor_scores)\n","        print(f'Average METEOR Score: {meteor_avg*100:.2f}')\n","    \n","    except Exception as error:  # OpenAI ChatGPT endpoint (gpt-3.5-turbo) may get stucked by too many queries from time to time\n","        \n","        print(error)\n"]},{"cell_type":"markdown","id":"2aabe9f8","metadata":{"id":"2aabe9f8"},"source":["<a name=\"21\"></a>\n","### **2.1 Zero-Shot Generation**\n","\n","Try 0-shot story ending generation (i.e., without any in-context examples).\n","\n","Create caches for saving model predictions, queries and reference story endings."]},{"cell_type":"code","execution_count":null,"id":"ff383572","metadata":{"id":"ff383572"},"outputs":[],"source":["generations_21 = []\n","queries_21 = []\n","reference_endings_21 = []"]},{"cell_type":"markdown","id":"c58400cf","metadata":{"id":"c58400cf"},"source":["Run the generation and evaluation.\n","\n","**Note:** Similar to Part 1, re-run the cell if it gets stucked."]},{"cell_type":"code","execution_count":null,"id":"bc252e8e","metadata":{"id":"bc252e8e"},"outputs":[],"source":["random.seed(seed)\n","np.random.seed(seed)\n","\n","run(train_samples_sg, test_data_sg, 0, generations_21, queries_21, reference_endings_21, task_name=\"2_1_shots0\")"]},{"cell_type":"markdown","id":"028cff13","metadata":{"id":"028cff13"},"source":["You can print the saved caches and compare the quality of the reference and model-generated story endings."]},{"cell_type":"code","execution_count":null,"id":"6e0b2dd1","metadata":{"id":"6e0b2dd1"},"outputs":[],"source":["print(\"Queries:\\n\"+queries_21[0])\n","print(\"GPT-3.5 Generation:\\n\"+generations_21[0])\n","print(\"Reference:\\n\"+reference_endings_21[0])"]},{"cell_type":"markdown","id":"ae4813db","metadata":{"id":"ae4813db"},"source":["<a name=\"22\"></a>\n","### **2.2 Few-Shot Generation**\n","\n","Try adding 5-shot in-context examples for this generation task."]},{"cell_type":"code","execution_count":null,"id":"89a6f67a","metadata":{"id":"89a6f67a"},"outputs":[],"source":["generations_22 = []\n","queries_22 = []\n","reference_endings_22 = []"]},{"cell_type":"code","execution_count":null,"id":"5267b3c5","metadata":{"id":"5267b3c5"},"outputs":[],"source":["random.seed(seed)\n","np.random.seed(seed)\n","\n","run(train_samples_sg, test_data_sg, 5, generations_22, queries_22, reference_endings_22, task_name=\"2_2_shots5\")"]},{"cell_type":"markdown","id":"44be2268","metadata":{"id":"44be2268"},"source":["**Question:** Do few-shot examples improve the model's story ending generation quality?"]},{"cell_type":"markdown","id":"c9bd1485","metadata":{"id":"c9bd1485"},"source":["You can print the saved caches and make more comparisons between the model generations in 2.1 and 2.2."]},{"cell_type":"code","execution_count":null,"id":"e028b9a4","metadata":{"id":"e028b9a4"},"outputs":[],"source":["print(\"Queries:\\n\"+queries_22[0])\n","print(\"GPT-3.5 Generation:\\n\"+generations_22[0])\n","print(\"Reference:\\n\"+reference_endings_22[0])"]},{"cell_type":"markdown","id":"2276b631","metadata":{"id":"2276b631"},"source":["<a name=\"23\"></a>\n","### **2.3 Add Instructions**\n","\n","Try 0-shot in-context learning with overall task introduction."]},{"cell_type":"code","execution_count":null,"id":"e7bcd744","metadata":{"id":"e7bcd744"},"outputs":[],"source":["generations_23 = []\n","queries_23 = []\n","reference_endings_23 = []"]},{"cell_type":"code","execution_count":null,"id":"efb203a4","metadata":{"id":"efb203a4"},"outputs":[],"source":["random.seed(seed)\n","np.random.seed(seed)\n","\n","introduction = \"Generate an ending of the given story.\"\n","run(train_samples_sg, test_data_sg, 0, generations_23, queries_23, reference_endings_23,\n","    introduction=introduction, task_name=\"2_3_intro\")"]},{"cell_type":"markdown","id":"2cd95e36","metadata":{"id":"2cd95e36"},"source":["**Question:** Does overall task instruction help improve the model's 0-shot story ending generation quality?"]},{"cell_type":"markdown","id":"a314a4db","metadata":{"id":"a314a4db"},"source":["You can print the saved caches and make more comparisons between the model generations in 2.1 and 2.3."]},{"cell_type":"code","execution_count":null,"id":"75485c15","metadata":{"id":"75485c15"},"outputs":[],"source":["print(\"Queries:\\n\"+queries_23[0])\n","print(\"GPT-3.5 Generation:\\n\"+generations_23[0])\n","print(\"Reference:\\n\"+reference_endings_23[0])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[]},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}