
## Reading References for Week 1

| Lecture | Readings                   |
|:-------:|:---------------------------|
| 1       |                            |
| 2       | [1] J. Eisenstein, [Introduction to natural language processing](https://mitpress.mit.edu/9780262042840/introduction-to-natural-language-processing). London, England: MIT Press, 2019. chapter 3.1 - 3.3 |
| 3       | [1] J. Eisenstein, [Introduction to natural language processing](https://mitpress.mit.edu/9780262042840/introduction-to-natural-language-processing). London, England: MIT Press, 2019. chapter 14.5 - 14.6 <br />[2] T. Mikolov, K. Chen, G. Corrado, and J. Dean, [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781). arXiv, 2013. <br />[3] Pennington, J., Socher, R., & Manning, C.D. (2014). GloVe: Global Vectors for Word Representation. Conference on Empirical Methods in Natural Language Processing. [Online]. Available: [https://aclanthology.org/D14-1162](https://aclanthology.org/D14-1162) <br />[4] Bojanowski, P., Grave, E., Joulin, A., & Mikolov, T. (2017). Enriching word vectors with subword information. Transactions of the association for computational linguistics. [Online]. Available: [https://aclanthology.org/Q17-1010](https://aclanthology.org/Q17-1010) <br />[5] Mikolov, T., Grave, E., Bojanowski, P., Puhrsch, C., & Joulin, A. (2018). Advances in pre-training distributed word representations. International Conference on Language Resources and Evaluation. [Online]. Available: [https://aclanthology.org/L18-1008](https://aclanthology.org/L18-1008) |

